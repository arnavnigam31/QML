{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5eb4166",
   "metadata": {},
   "source": [
    "# Task 11\n",
    "\n",
    "We will be implementing a hybrid neural network that combines MLP with quantum computing.\n",
    "\n",
    "First import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5afb22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pennylane as qml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b798423",
   "metadata": {},
   "source": [
    "We will be using 4 defualt qubits of qml "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50ae06a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64) # to set datatype\n",
    "\n",
    "n_qubits = 4\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8450b7",
   "metadata": {},
   "source": [
    "### Circuit \n",
    "\n",
    "First apply RY gate\n",
    "\n",
    "Then apply Cnot gate to all adjacent \n",
    "\n",
    "Then again apply RY gate to all\n",
    "\n",
    "And finally use Pauliz to to get expectation value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1087592c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: ──RY(0.30)──╭●──RY(-0.39)──────────────────────┤  <Z>\n",
      "1: ──RY(0.44)──╰X─╭●──────────RY(1.01)────────────┤  <Z>\n",
      "2: ──RY(0.09)─────╰X─────────╭●─────────RY(1.39)──┤  <Z>\n",
      "3: ──RY(-1.36)───────────────╰X─────────RY(-0.04)─┤  <Z>\n"
     ]
    }
   ],
   "source": [
    "@qml.qnode(dev, interface=\"torch\")\n",
    "def circuit(params):\n",
    "    for i in range(n_qubits):\n",
    "        qml.RY(params[0, i], wires=i)\n",
    "        \n",
    "    for i in range(n_qubits - 1):\n",
    "        qml.CNOT(wires=[i, i+1])\n",
    "    \n",
    "    for i in range(n_qubits):\n",
    "        qml.RY(params[1, i], wires=i)\n",
    "    \n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
    "\n",
    "trial_circuit = torch.randn((2, n_qubits), dtype=torch.float64)\n",
    "# sample circuit for understanding\n",
    "drawer = qml.draw(circuit)\n",
    "print(drawer(trial_circuit))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701fd31a",
   "metadata": {},
   "source": [
    "# MLP\n",
    "\n",
    "This Multi-Layer Perceptron (MLP) maps normally distributed data to PQC parameters.\n",
    "\n",
    "`fc1`: Fully connected layer (`input_dim → hidden_dim`).<br>\n",
    "`fc2`: Fully connected layer (`hidden_dim → hidden_dim`).<br>\n",
    "`fc3`: Fully connected layer (`hidden_dim → output_dim`).<br>\n",
    "Uses ReLU activations for non-linearity.<br>\n",
    "Output (`output_dim = 2 * n_qubits`) provides the parameters for the PQC.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc961a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5e5bae",
   "metadata": {},
   "source": [
    "### Hyperparameters \n",
    "\n",
    "\n",
    "The tolerance defines how close quantum circuit outputs must be to targets to count as accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a7beee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 4                   # Dimensionality of input data\n",
    "hidden_dim = 16                 # Hidden layer size for the MLP\n",
    "output_dim = 2 * n_qubits       # Total parameters for the PQC (2 layers x 4 qubits)\n",
    "learning_rate = 0.01\n",
    "n_epochs = 200\n",
    "batch_size = 16\n",
    "\n",
    "# Instantiate the MLP and the optimizer\n",
    "mlp = MLP(input_dim, hidden_dim, output_dim).double()\n",
    "optimizer = optim.Adam(mlp.parameters(), lr=learning_rate)\n",
    "mse_loss = nn.MSELoss()\n",
    "\n",
    "# Tolerance\n",
    "tol = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e965e483",
   "metadata": {},
   "source": [
    "**Data Generation**<br>\n",
    "\n",
    "Generate normally distributed inputs (x).<br>\n",
    "\n",
    "Apply tanh to bound target values between -1 and 1.<br>\n",
    "\n",
    "**Processing Each Sample**<br>\n",
    "\n",
    "MLP predicts PQC parameters and reshapes them into [2, n_qubits].<br>\n",
    "\n",
    "The quantum circuit is executed with these parameters.<br>\n",
    "\n",
    "The outputs are collected into a batch tensor.<br>\n",
    "\n",
    "**Loss Calculation**<br>\n",
    "\n",
    "Mean Squared Error (MSE) loss is computed against the target.<br>\n",
    "\n",
    "**Backpropagation**<br>\n",
    "\n",
    "`loss.backward()` updates both the MLP and quantum parameters.<br>\n",
    "\n",
    "`optimizer.step()` updates the weights.<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe78ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200 - Loss: 0.002825 - Accuracy: 92.19%\n",
      "Epoch 11/200 - Loss: 0.001792 - Accuracy: 93.75%\n",
      "Epoch 21/200 - Loss: 0.003642 - Accuracy: 95.31%\n",
      "Epoch 31/200 - Loss: 0.000834 - Accuracy: 100.00%\n",
      "Epoch 41/200 - Loss: 0.001483 - Accuracy: 100.00%\n",
      "Epoch 51/200 - Loss: 0.001748 - Accuracy: 96.88%\n",
      "Epoch 61/200 - Loss: 0.002243 - Accuracy: 96.88%\n",
      "Epoch 71/200 - Loss: 0.001135 - Accuracy: 98.44%\n",
      "Epoch 81/200 - Loss: 0.001370 - Accuracy: 98.44%\n",
      "Epoch 91/200 - Loss: 0.004487 - Accuracy: 96.88%\n",
      "Epoch 101/200 - Loss: 0.001008 - Accuracy: 100.00%\n",
      "Epoch 111/200 - Loss: 0.001386 - Accuracy: 98.44%\n",
      "Epoch 121/200 - Loss: 0.001377 - Accuracy: 98.44%\n",
      "Epoch 131/200 - Loss: 0.001163 - Accuracy: 98.44%\n",
      "Epoch 141/200 - Loss: 0.001521 - Accuracy: 96.88%\n",
      "Epoch 151/200 - Loss: 0.001522 - Accuracy: 98.44%\n",
      "Epoch 161/200 - Loss: 0.001091 - Accuracy: 100.00%\n",
      "Epoch 171/200 - Loss: 0.000922 - Accuracy: 100.00%\n",
      "Epoch 181/200 - Loss: 0.001470 - Accuracy: 98.44%\n",
      "Epoch 191/200 - Loss: 0.001081 - Accuracy: 100.00%\n",
      "Best accuracy = 100.0\n"
     ]
    }
   ],
   "source": [
    "best_acc=0\n",
    "for epoch in range(n_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # random data normally distributed\n",
    "    x = torch.randn((batch_size, input_dim), dtype=torch.float64)\n",
    "    \n",
    "    # For a target, we use tanh as range is[-1,1]\n",
    "    target = torch.tanh(x)\n",
    "    \n",
    "    outputs = []\n",
    "    for sample in x:\n",
    "        # Predict PQC parameters and reshape to [2, n_qubits]\n",
    "        params = mlp(sample).reshape(2, n_qubits)\n",
    "        # Run the quantum circuit and collect expectation values\n",
    "        exp_vals = torch.stack(circuit(params))\n",
    "        outputs.append(exp_vals)\n",
    "    \n",
    "    outputs = torch.stack(outputs)  # shape: [batch_size, n_qubits]\n",
    "    \n",
    "    # Compute MSE loss between circuit outputs and the target (first n_qubits dimensions)\n",
    "    loss = mse_loss(outputs, target[:, :n_qubits])\n",
    "    \n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Compute accuracy: percentage of output elements within the tolerance of the target.\n",
    "    accuracy = (torch.abs(outputs - target[:, :n_qubits]) < tol).float().mean() * 100.0\n",
    "    if(accuracy>best_acc):\n",
    "        best_acc=accuracy\n",
    "    if(epoch%10==0):\n",
    "        print(f\"Epoch {epoch+1}/{n_epochs} - Loss: {loss.item():.6f} - Accuracy: {accuracy.item():.2f}%\")\n",
    "\n",
    "print(f\"Best accuracy = {best_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac70df32",
   "metadata": {},
   "source": [
    "We have achieved 100% accuracy beacuse the dataset is simple and randomly generated. This value will be changed if we will rerun the code."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
