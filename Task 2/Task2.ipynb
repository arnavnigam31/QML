{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4a39e77-996f-4f32-ae48-c61a8a4ef874",
   "metadata": {},
   "source": [
    "# Task 2:Classical GNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fded3a-9887-4311-9187-725f1e9e8e1a",
   "metadata": {},
   "source": [
    "Graph Neural Network are used to handle the data in the form of vertices and edges unline CNN,RNN etc.\n",
    "It helps to establish relationship between entities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d605d276-349e-4abb-aab7-76c27b68da86",
   "metadata": {},
   "source": [
    "We will first start by importing all the required libraries and will be using  **pytorch** for implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4c90e98-dd6d-4a1a-bf63-c810bc8fc7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.data import InMemoryDataset, Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from torch_cluster import knn_graph\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import GCNConv, GATConv, GINConv, BatchNorm, global_mean_pool\n",
    "from torch.nn import BatchNorm1d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b406d7ac-b8ad-4de9-90a8-4dcbe45516e8",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8786d34-7269-4b9f-a6d8-94d9619c96dd",
   "metadata": {},
   "source": [
    "We will create a class for QGDataset.\n",
    "\n",
    "The dataset is in .npz files.\n",
    "Since there are many files we will join all the files and then store the processed data in data.pt \n",
    "\n",
    "The dataset has 2 labels X and Y \n",
    "### X field\n",
    "X contain a 2D matrix that is collection of particles and each particles has 4 field \n",
    "\n",
    "X.shape= (number of jets,number of particle,features)\n",
    "\n",
    "\n",
    "The number of jets are the total jets in the data set\n",
    "\n",
    "\n",
    "The number of particles is total particles in each jet\n",
    "\n",
    "The features =4 ie pT, eta, phi and PDG ID\n",
    "\n",
    "### Y field\n",
    "Y.shape= (num of jets)\n",
    "\n",
    "It is a 1D matrix that contain only 0 and 1 for Gluon and Quark "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da2a657-dc79-4d7a-b55c-904b8eedc1ae",
   "metadata": {},
   "source": [
    "For X we are using float32 as datatype because of memory constraint on the system\n",
    "\n",
    "We will be using only first 3 features of X ie pT, phi and eta and we will not use PDGID beacuse it is just the id of particle and it does no define any spatial behaviour "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6a73d9-b08e-43e1-9365-01ae8502fcea",
   "metadata": {},
   "source": [
    "### Graph\n",
    "\n",
    "We will be using KNN to create a graph\n",
    "\n",
    "Node/Vertices= Particle in a Jet\n",
    "\n",
    "Edges= Relationship between particles based on pT, phi, eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f8807a-c533-4a04-8a61-19fda91b5cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QGDataset(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super(QGDataset, self).__init__(root, transform, pre_transform)\n",
    "        path = self.processed_paths[0]\n",
    "        if os.path.exists(path):\n",
    "            self.data, self.slices = torch.load(path)\n",
    "        else:\n",
    "            self.process()\n",
    "            self.data, self.slices = torch.load(path)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        # All .npz files in the raw directory\n",
    "        return glob.glob(os.path.join(self.raw_dir, '*.npz'))\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['processed_data.pt']\n",
    "\n",
    "    def process(self):\n",
    "        data_list = []\n",
    "        for fpath in tqdm(self.raw_file_names, desc=\"Processing .npz Files\"):\n",
    "            npz = np.load(fpath, mmap_mode='r')\n",
    "            # Use the keys 'X' and 'y' as found in your files\n",
    "            features = npz['X'].astype(np.float32)  # shape: (num_jets, num_particles, num_features)\n",
    "            labels = npz['y'].astype(np.int64)      # shape: (num_jets,)\n",
    "            num_jets, num_particles, num_feats = features.shape\n",
    "\n",
    "            for i in range(num_jets):\n",
    "                x_np = features[i]  # shape: (num_particles, num_feats)\n",
    "                mean = np.mean(x_np, axis=0, keepdims=True)\n",
    "                std = np.std(x_np, axis=0, keepdims=True) + 1e-6\n",
    "                x_np_norm = (x_np - mean) / std\n",
    "\n",
    "                x = torch.tensor(x_np_norm, dtype=torch.float32)\n",
    "                y = torch.tensor([labels[i]], dtype=torch.long)\n",
    "\n",
    "                # Build graph: use first three features (pT, η, ϕ) for KNN\n",
    "                coords = x[:, :3]\n",
    "                edge_index = knn_graph(coords, k=10, loop=False)\n",
    "                data_obj = Data(x=x, edge_index=edge_index, y=y)\n",
    "                data_list.append(data_obj)\n",
    "\n",
    "        self.data, self.slices = self.collate(data_list)\n",
    "        torch.save((self.data, self.slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3173e77-32e1-4406-9890-d0061353f687",
   "metadata": {},
   "source": [
    "## First Model : Simple GCN\n",
    "\n",
    "### 1. Model Components  \n",
    "<code>def __init__(self, in_channels, hidden_dim=64, out_dim=2):</code>  \n",
    "The `in_channels` is the number of input features per node = 3 (`pT, η, ϕ`).<br>  \n",
    "`hidden_dim=64`: Hidden layer size.<br>  \n",
    "`out_dim = 2`: We have only 2 outputs (0 for Gluon, 1 for Quark).<br>  \n",
    "\n",
    "---\n",
    "\n",
    "### 2. Layers in the Model  \n",
    "<code>self.conv1 = GCNConv(in_channels, hidden_dim)</code>  \n",
    "Applies the first Graph Convolutional Layer, which extracts meaningful features from input nodes.<br>  \n",
    "\n",
    "<code>self.conv2 = GCNConv(hidden_dim, hidden_dim)</code>  \n",
    "A second Graph Convolutional Layer for refining learned representations.<br>  \n",
    "\n",
    "<code>self.lin = torch.nn.Linear(hidden_dim, out_dim)</code>  \n",
    "A fully connected layer that converts the graph representation into logits for classification.<br>  \n",
    "\n",
    "---\n",
    "\n",
    "### 3. Forward Pass  \n",
    "<code>def forward(self, x, edge_index, batch):</code>  \n",
    "Defines how input data passes through the model.<br>  \n",
    "\n",
    "#### 1st GCN Layer- Non-Linearity (ReLU)  \n",
    "<code>x = self.conv1(x, edge_index)</code><br>  \n",
    "Applies the first graph convolution (message passing).<br>  \n",
    "<code>x = F.relu(x)</code><br>  \n",
    "Uses ReLU activation to introduce non-linearity.<br>  \n",
    "\n",
    "#### 2nd GCN Layer - Non-Linearity (ReLU)  \n",
    "<code>x = self.conv2(x, edge_index)</code><br>  \n",
    "Refines the node features based on graph connections.<br>  \n",
    "<code>x = F.relu(x)</code><br>  \n",
    "Applies another non-linearity.<br>  \n",
    "\n",
    "#### Global Pooling  \n",
    "<code>x = global_mean_pool(x, batch)</code><br>  \n",
    "Aggregates all node features to form a single graph-level feature vector.<br>  \n",
    "\n",
    "#### Fully Connected Output  \n",
    "<code>x = self.lin(x)</code><br>  \n",
    "Final classification layer for binary output (Quark vs Gluon).<br>  \n",
    "<code>return x</code><br>  \n",
    "Returns logits for classification.<br>  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "866060b4-cad3-4878-9af5-4c003d9c543d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleGCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_dim=64, out_dim=2):\n",
    "        super(SimpleGCN, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.lin = torch.nn.Linear(hidden_dim, out_dim)\n",
    "    \n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = global_mean_pool(x, batch)\n",
    "        return self.lin(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b808ed61-db46-4d75-a1ad-15040bf0c682",
   "metadata": {},
   "source": [
    "## Second Model: GCNModel\n",
    "\n",
    "### 1. Model Components  \n",
    "<code>def __init__(self, in_channels, hidden_dim=256, out_dim=2, dropout=0.3):</code>  \n",
    "- `in_channels`: Number of input features per node = 3 (`pT, η, ϕ`).  \n",
    "- `hidden_dim=256`: Size of the hidden layers for feature extraction.  \n",
    "- `out_dim=2`: We have only 2 output classes (0 for Gluon, 1 for Quark).  \n",
    "- `dropout=0.3`: Probability of randomly dropping neurons to prevent overfitting.  \n",
    "\n",
    "---\n",
    "\n",
    "### 2. Layers in the Model  \n",
    "<code>self.conv1 = GCNConv(in_channels, hidden_dim)</code>  \n",
    "First Graph Convolutional Layer to process input node features.<br>  \n",
    "\n",
    "<code>self.bn1 = BatchNorm(hidden_dim)</code>  \n",
    "Batch Normalization to stabilize training and speed up convergence.<br>  \n",
    "\n",
    "<code>self.conv2 = GCNConv(hidden_dim, hidden_dim)</code>  \n",
    "Second Graph Convolutional Layer for deeper feature learning.<br>  \n",
    "\n",
    "<code>self.bn2 = BatchNorm(hidden_dim)</code>  \n",
    "Another Batch Normalization for improved stability.<br>  \n",
    "\n",
    "<code>self.dropout = dropout</code>  \n",
    "Dropout to prevent overfitting during training.<br>  \n",
    "\n",
    "<code>self.lin = torch.nn.Linear(hidden_dim, out_dim)</code>  \n",
    "Fully connected layer for final classification.<br>  \n",
    "\n",
    "---\n",
    "\n",
    "### 3. Forward Pass  \n",
    "<code>def forward(self, x, edge_index, batch):</code>  \n",
    "Defines how data moves through the model.<br>  \n",
    "\n",
    "#### 1st GCN Layer → BatchNorm → ReLU → Dropout  \n",
    "<code>x = self.conv1(x, edge_index)</code>  \n",
    "Applies the first graph convolution layer.<br>  \n",
    "\n",
    "<code>x = self.bn1(x)</code>  \n",
    "Normalizes feature distribution.<br>  \n",
    "\n",
    "<code>x = F.relu(x)</code>  \n",
    "Applies ReLU activation for non-linearity.<br>  \n",
    "\n",
    "<code>x = F.dropout(x, p=self.dropout, training=self.training)</code>  \n",
    "Randomly drops some neurons for regularization.<br>  \n",
    "\n",
    "#### 2nd GCN Layer → BatchNorm → ReLU  \n",
    "<code>x = self.conv2(x, edge_index)</code>  \n",
    "Extracts higher-level features from the graph.<br>  \n",
    "\n",
    "<code>x = self.bn2(x)</code>  \n",
    "Batch normalization to maintain stable distributions.<br>  \n",
    "\n",
    "<code>x = F.relu(x)</code>  \n",
    "Applies another ReLU activation.<br>  \n",
    "\n",
    "#### Global Pooling  \n",
    "<code>x = global_mean_pool(x, batch)</code>  \n",
    "Aggregates features across all nodes in the graph.<br>  \n",
    "\n",
    "#### Fully Connected Output  \n",
    "<code>x = self.lin(x)</code>  \n",
    "Final classification layer for predicting Quark (1) or Gluon (0).<br>  \n",
    "\n",
    "<code>return x</code>  \n",
    "Returns the logits for classification.<br>  \n",
    "\n",
    "---  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e14f94d8-abe9-4d5c-9dc8-9edc9931486e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNModel(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_dim=256, out_dim=2, dropout=0.3):\n",
    "        super(GCNModel, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_dim)\n",
    "        self.bn1 = BatchNorm1d(hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.bn2 = BatchNorm1d(hidden_dim)\n",
    "        self.dropout = dropout\n",
    "        self.lin = torch.nn.Linear(hidden_dim, out_dim)\n",
    "    \n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = F.relu(self.bn1(self.conv1(x, edge_index)))\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = F.relu(self.bn2(self.conv2(x, edge_index)))\n",
    "        x = global_mean_pool(x, batch)\n",
    "        return self.lin(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49021143-5d34-4725-92d2-edd5fa93ff05",
   "metadata": {},
   "source": [
    "## Third Model : GATModel \n",
    "\n",
    "### 1. Model Components  \n",
    "<code>def __init__(self, in_channels, hidden_dim=256, out_dim=2, heads=4, dropout=0.3):</code>  \n",
    "- `in_channels`: Number of input features per node = 3 (`pT, η, ϕ`).  \n",
    "- `hidden_dim=256`: Size of the hidden layers for feature extraction.  \n",
    "- `out_dim=2`: We have only 2 output classes (0 for Gluon, 1 for Quark).  \n",
    "- `heads=4`: Number of attention heads in the first GAT layer.  \n",
    "- `dropout=0.3`: Dropout rate to prevent overfitting.  \n",
    "\n",
    "---\n",
    "\n",
    "### 2. Layers in the Model  \n",
    "<code>self.conv1 = GATConv(in_channels, hidden_dim, heads=heads, concat=True)</code>  \n",
    "First Graph Attention Layer (GAT) with multi-head attention (concatenated output).<br>  \n",
    "\n",
    "<code>self.bn1 = BatchNorm(hidden_dim * heads)</code>  \n",
    "Batch Normalization to stabilize training and speed up convergence.<br>  \n",
    "\n",
    "<code>self.conv2 = GATConv(hidden_dim * heads, hidden_dim, heads=1, concat=False)</code>  \n",
    "Second GAT Layer (single-head) to refine learned features.<br>  \n",
    "\n",
    "<code>self.bn2 = BatchNorm(hidden_dim)</code>  \n",
    "Another Batch Normalization for improved stability.<br>  \n",
    "\n",
    "<code>self.dropout = dropout</code>  \n",
    "Dropout to prevent overfitting during training.<br>  \n",
    "\n",
    "<code>self.lin = torch.nn.Linear(hidden_dim, out_dim)</code>  \n",
    "Fully connected layer for final classification.<br>  \n",
    "\n",
    "---\n",
    "\n",
    "### 3. Forward Pass  \n",
    "<code>def forward(self, x, edge_index, batch):</code>  \n",
    "Defines how data moves through the model.<br>  \n",
    "\n",
    "#### 1st GAT Layer → BatchNorm → ELU → Dropout  \n",
    "<code>x = self.conv1(x, edge_index)</code>  \n",
    "Applies the first graph attention convolution.<br>  \n",
    "\n",
    "<code>x = self.bn1(x)</code>  \n",
    "Normalizes feature distribution.<br>  \n",
    "\n",
    "<code>x = F.elu(x)</code>  \n",
    "Applies ELU activation for smooth feature transformation.<br>  \n",
    "\n",
    "<code>x = F.dropout(x, p=self.dropout, training=self.training)</code>  \n",
    "Randomly drops some neurons for regularization.<br>  \n",
    "\n",
    "#### 2nd GAT Layer → BatchNorm → ELU  \n",
    "<code>x = self.conv2(x, edge_index)</code>  \n",
    "Extracts refined features from the graph.<br>  \n",
    "\n",
    "<code>x = self.bn2(x)</code>  \n",
    "Batch normalization to maintain stable distributions.<br>  \n",
    "\n",
    "<code>x = F.elu(x)</code>  \n",
    "Applies another ELU activation.<br>  \n",
    "\n",
    "#### Global Pooling  \n",
    "<code>x = global_mean_pool(x, batch)</code>  \n",
    "Aggregates features across all nodes in the graph.<br>  \n",
    "\n",
    "#### Fully Connected Output  \n",
    "<code>x = self.lin(x)</code>  \n",
    "Final classification layer for predicting Quark (1) or Gluon (0).<br>  \n",
    "\n",
    "<code>return x</code>  \n",
    "Returns the logits for classification.<br>  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b11c2500-be9c-4b3e-ba24-2d47499ff394",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATModel(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_dim=256, out_dim=2, heads=4, dropout=0.3):\n",
    "        super(GATModel, self).__init__()\n",
    "        self.conv1 = GATConv(in_channels, hidden_dim, heads=heads, concat=True)\n",
    "        self.bn1 = BatchNorm1d(hidden_dim * heads)\n",
    "        self.conv2 = GATConv(hidden_dim * heads, hidden_dim, heads=1, concat=False)\n",
    "        self.bn2 = BatchNorm1d(hidden_dim)\n",
    "        self.dropout = dropout\n",
    "        self.lin = torch.nn.Linear(hidden_dim, out_dim)\n",
    "    \n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = F.elu(self.bn1(self.conv1(x, edge_index)))\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = F.elu(self.bn2(self.conv2(x, edge_index)))\n",
    "        x = global_mean_pool(x, batch)\n",
    "        return self.lin(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2abd54",
   "metadata": {},
   "source": [
    "# Fourth Model: Residual GCN\n",
    "\n",
    "### 1. Model Components\n",
    "<code>def __init__(self, in_channels, hidden_dim=256, out_dim=2, dropout=0.3):</code>\n",
    "- **in_channels**: Number of input features per node (e.g., 3 for pT, η, ϕ).  \n",
    "- **hidden_dim = 256**: Size of the hidden layers used for feature extraction.  \n",
    "- **out_dim = 2**: Number of output classes (e.g., 0 for Gluon, 1 for Quark).  \n",
    "- **dropout = 0.3**: Dropout rate to help prevent overfitting.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Layers in the Model\n",
    "- **<code>self.conv1 = GCNConv(in_channels, hidden_dim)</code>**  \n",
    "  The first graph convolutional layer, which transforms input features into a hidden representation.\n",
    "\n",
    "- **<code>self.bn1 = BatchNorm1d(hidden_dim)</code>**  \n",
    "  Batch normalization for the output of the first GCN layer to stabilize and speed up training.\n",
    "\n",
    "- **<code>self.conv2 = GCNConv(hidden_dim, hidden_dim)</code>**  \n",
    "  The second GCN layer that further processes the features.\n",
    "\n",
    "- **<code>self.bn2 = BatchNorm1d(hidden_dim)</code>**  \n",
    "  Batch normalization applied after the second GCN layer.\n",
    "\n",
    "- **<code>self.conv3 = GCNConv(hidden_dim, hidden_dim)</code>**  \n",
    "  The third GCN layer which extracts deeper features from the graph.\n",
    "\n",
    "- **<code>self.bn3 = BatchNorm1d(hidden_dim)</code>**  \n",
    "  Batch normalization applied to the output of the third GCN layer.\n",
    "\n",
    "- **<code>self.lin = torch.nn.Linear(hidden_dim, out_dim)</code>**  \n",
    "  A fully connected layer that maps the final hidden representation to the output classes.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Forward Pass\n",
    "<code>def forward(self, x, edge_index, batch):</code>\n",
    "\n",
    "1. **First GCN Layer:**  \n",
    "   <code>x1 = F.relu(self.bn1(self.conv1(x, edge_index)))</code>  \n",
    "   - Applies the first GCN layer, followed by batch normalization and ReLU activation.\n",
    "\n",
    "2. **Second GCN Layer:**  \n",
    "   <code>x2 = F.relu(self.bn2(self.conv2(x1, edge_index)))</code>  \n",
    "   - Applies the second GCN layer on the output of the first layer, followed by batch normalization and ReLU activation.\n",
    "\n",
    "3. **Third GCN Layer with Residual Connection:**  \n",
    "   <code>x3 = F.relu(self.bn3(self.conv3(x2, edge_index)) + x1)</code>  \n",
    "   - The output of the third GCN layer is added to the output of the first layer (residual connection) to help preserve initial features, then batch normalization and ReLU activation are applied.\n",
    "\n",
    "4. **Global Pooling:**  \n",
    "   <code>x = global_mean_pool(x3, batch)</code>  \n",
    "   - Aggregates node features into a single graph-level representation by taking the mean of all node features.\n",
    "\n",
    "5. **Final Classification:**  \n",
    "   <code>x = self.lin(x)</code>  \n",
    "   - The pooled features are passed through a linear layer to produce the final logits for classification.\n",
    "\n",
    "6. **Return:**  \n",
    "   <code>return x</code>  \n",
    "   - Returns the output logits.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce20b3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualGCNModel(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_dim=256, out_dim=2, dropout=0.3):\n",
    "        super(ResidualGCNModel, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_dim)\n",
    "        self.bn1 = BatchNorm1d(hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.bn2 = BatchNorm1d(hidden_dim)\n",
    "        self.conv3 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.bn3 = BatchNorm1d(hidden_dim)\n",
    "        self.dropout = dropout\n",
    "        self.lin = torch.nn.Linear(hidden_dim, out_dim)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x1 = F.relu(self.bn1(self.conv1(x, edge_index)))\n",
    "        x2 = F.relu(self.bn2(self.conv2(x1, edge_index)))\n",
    "        # Residual connection: add output of first layer (x1) to third layer's output\n",
    "        x3 = F.relu(self.bn3(self.conv3(x2, edge_index)) + x1)\n",
    "        x = global_mean_pool(x3, batch)\n",
    "        x = self.lin(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c17defa-178c-4469-a43e-37c354a15757",
   "metadata": {},
   "source": [
    "## Training \n",
    "\n",
    "### 1. Cross-Entropy Loss \n",
    "(`F.cross_entropy(out, data.y)`)<br>\n",
    "It measures how bad model predictions are.\n",
    "\n",
    "- The model gives a **score** for each class (e.g., **quark** or **gluon**), but these scores might not be correct.  \n",
    "- The **cross-entropy loss** tells us **how far off** the model’s predictions are from the actual answers.  \n",
    "- The goal is to **reduce this loss** so the model makes better predictions over time.  \n",
    "\n",
    "**Example:**  \n",
    "If the actual label is **1 (quark)** and the model predicts **[0.1, 0.9]**, meaning it's **90% sure it’s a quark**, the loss is **small** (good!).  \n",
    "If the model predicts **[0.9, 0.1]**, meaning it's **90% sure it’s a gluon**, the loss is **large** (bad!).  \n",
    "\n",
    "---\n",
    "\n",
    "### 2. Optimizer \n",
    "(`optimizer.step()`)<br>\n",
    "- It helps to change parameters after mistakes\n",
    "- It looks at the **cross-entropy loss** and decides how to **adjust the model’s settings (weights)** to improve its predictions.  \n",
    "- Popular optimizers:  \n",
    "  - **SGD (Slow Learner)** – Adjusts weights little by little.  \n",
    "  - **Adam (Smart Learner)** – Learns **faster** by adjusting weights differently for each part of the model.  \n",
    "\n",
    "---\n",
    "\n",
    "### 3. `loss.backward()`\n",
    "- This tells the model **which parts of itself are responsible for the mistake** (computing gradients).  \n",
    "- It helps figure out which **weights** should be changed and by how much.  \n",
    "\n",
    "---\n",
    "\n",
    "### 4. `model.train()` \n",
    "- **`model.train()`** – The model is **actively learning**. It allows techniques like **dropout** (randomly ignoring some neurons) to **prevent overfitting**.\n",
    "### 5. `model.eval()`   \n",
    "- **`model.eval()`** – The model is in **testing mode**, meaning no tricks like dropout—it just makes predictions **as accurately as possible**.  \n",
    "\n",
    "---\n",
    "\n",
    "## How It All Works Together  \n",
    "1. The model makes a **guess** (prediction).  \n",
    "2. The **cross-entropy loss** checks how wrong the guess is.  \n",
    "3. **Backpropagation (`loss.backward()`)** finds out **what to fix**.  \n",
    "4. The **optimizer (`optimizer.step()`)** updates the model to **reduce errors** next time.  \n",
    "5. Over time, the model **gets better at classifying quarks and gluons!**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "548ba759-aa44-4d56-a37f-dff03859e919",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in tqdm(loader, desc=\"Training\"):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        loss = F.cross_entropy(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * data.num_graphs\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "def test(model, loader, device):\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        with torch.no_grad():\n",
    "            out = model(data.x, data.edge_index, data.batch)\n",
    "            pred = out.argmax(dim=1)\n",
    "            y_true.extend(data.y.cpu().numpy())\n",
    "            y_pred.extend(pred.cpu().numpy())\n",
    "    return accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2a0cd61-d678-44c5-9f07-905dff9586d2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arnav\\AppData\\Local\\Temp\\ipykernel_1468\\2633872568.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.data, self.slices = torch.load(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training SimpleGCN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:01<00:00, 87.22it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01, Loss: 0.6852, Test Accuracy: 0.6830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:00<00:00, 162.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02, Loss: 0.6056, Test Accuracy: 0.6760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:00<00:00, 164.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03, Loss: 0.5649, Test Accuracy: 0.7460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:00<00:00, 161.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04, Loss: 0.5452, Test Accuracy: 0.7450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:00<00:00, 163.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05, Loss: 0.5377, Test Accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:00<00:00, 160.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06, Loss: 0.5303, Test Accuracy: 0.7580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:00<00:00, 161.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07, Loss: 0.5316, Test Accuracy: 0.7570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:00<00:00, 161.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08, Loss: 0.5314, Test Accuracy: 0.7520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:00<00:00, 160.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09, Loss: 0.5313, Test Accuracy: 0.7580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:00<00:00, 162.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.5274, Test Accuracy: 0.7440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:00<00:00, 158.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 0.5289, Test Accuracy: 0.7530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:00<00:00, 161.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Loss: 0.5261, Test Accuracy: 0.7490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:00<00:00, 157.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Loss: 0.5254, Test Accuracy: 0.7490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:00<00:00, 145.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Loss: 0.5253, Test Accuracy: 0.7450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:00<00:00, 160.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Loss: 0.5235, Test Accuracy: 0.7640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:00<00:00, 146.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Loss: 0.5279, Test Accuracy: 0.7580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:00<00:00, 153.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Loss: 0.5248, Test Accuracy: 0.7590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:00<00:00, 163.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Loss: 0.5283, Test Accuracy: 0.7650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:00<00:00, 166.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Loss: 0.5240, Test Accuracy: 0.7630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:00<00:00, 166.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Loss: 0.5233, Test Accuracy: 0.7420\n",
      "Best accuracy 0.765\n",
      "\n",
      "Training GCNModel...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:01<00:00, 75.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01, Loss: 0.5664, Test Accuracy: 0.6950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:01<00:00, 76.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02, Loss: 0.5379, Test Accuracy: 0.7010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:01<00:00, 75.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03, Loss: 0.5312, Test Accuracy: 0.7330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:01<00:00, 75.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04, Loss: 0.5338, Test Accuracy: 0.7240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:01<00:00, 75.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05, Loss: 0.5276, Test Accuracy: 0.7730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:01<00:00, 75.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06, Loss: 0.5300, Test Accuracy: 0.7570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:01<00:00, 76.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07, Loss: 0.5258, Test Accuracy: 0.7580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:01<00:00, 75.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08, Loss: 0.5243, Test Accuracy: 0.7690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:01<00:00, 76.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09, Loss: 0.5253, Test Accuracy: 0.7520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:01<00:00, 76.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.5228, Test Accuracy: 0.7670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:01<00:00, 76.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 0.5249, Test Accuracy: 0.7620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:01<00:00, 76.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Loss: 0.5307, Test Accuracy: 0.7330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:01<00:00, 75.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Loss: 0.5232, Test Accuracy: 0.7810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:01<00:00, 76.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Loss: 0.5218, Test Accuracy: 0.7740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:01<00:00, 75.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Loss: 0.5242, Test Accuracy: 0.7620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:01<00:00, 75.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Loss: 0.5253, Test Accuracy: 0.7640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:01<00:00, 76.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Loss: 0.5241, Test Accuracy: 0.7340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:01<00:00, 75.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Loss: 0.5222, Test Accuracy: 0.7720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:01<00:00, 76.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Loss: 0.5230, Test Accuracy: 0.7790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:01<00:00, 76.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Loss: 0.5236, Test Accuracy: 0.7790\n",
      "Best accuracy 0.781\n",
      "\n",
      "Training GATModel...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:04<00:00, 26.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01, Loss: 0.5487, Test Accuracy: 0.7170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:04<00:00, 26.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02, Loss: 0.5261, Test Accuracy: 0.7690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:04<00:00, 26.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03, Loss: 0.5224, Test Accuracy: 0.7740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:04<00:00, 26.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04, Loss: 0.5157, Test Accuracy: 0.7710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:04<00:00, 26.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05, Loss: 0.5276, Test Accuracy: 0.7460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:04<00:00, 26.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06, Loss: 0.5213, Test Accuracy: 0.7690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:04<00:00, 26.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07, Loss: 0.5208, Test Accuracy: 0.7260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:04<00:00, 26.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08, Loss: 0.5191, Test Accuracy: 0.7600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:04<00:00, 26.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09, Loss: 0.5252, Test Accuracy: 0.7590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:04<00:00, 26.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.5200, Test Accuracy: 0.7610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:04<00:00, 26.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 0.5241, Test Accuracy: 0.7400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:04<00:00, 26.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Loss: 0.5194, Test Accuracy: 0.7580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:04<00:00, 26.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Loss: 0.5157, Test Accuracy: 0.7520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:04<00:00, 26.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Loss: 0.5180, Test Accuracy: 0.7770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:04<00:00, 26.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Loss: 0.5192, Test Accuracy: 0.7610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:04<00:00, 26.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Loss: 0.5194, Test Accuracy: 0.7700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:04<00:00, 26.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Loss: 0.5200, Test Accuracy: 0.7720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:04<00:00, 26.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Loss: 0.5210, Test Accuracy: 0.7720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:04<00:00, 26.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Loss: 0.5216, Test Accuracy: 0.7710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:04<00:00, 26.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Loss: 0.5234, Test Accuracy: 0.7680\n",
      "Best accuracy 0.777\n",
      "\n",
      "Training ResidualGCNModel...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:02<00:00, 54.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01, Loss: 0.5456, Test Accuracy: 0.7620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:02<00:00, 54.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02, Loss: 0.5303, Test Accuracy: 0.7250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:02<00:00, 54.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03, Loss: 0.5317, Test Accuracy: 0.7710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:02<00:00, 54.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04, Loss: 0.5214, Test Accuracy: 0.7440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:02<00:00, 54.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05, Loss: 0.5295, Test Accuracy: 0.7790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:02<00:00, 54.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06, Loss: 0.5256, Test Accuracy: 0.7770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:02<00:00, 54.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07, Loss: 0.5184, Test Accuracy: 0.7780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:02<00:00, 54.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08, Loss: 0.5175, Test Accuracy: 0.7560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:02<00:00, 54.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09, Loss: 0.5210, Test Accuracy: 0.7530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:02<00:00, 54.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.5224, Test Accuracy: 0.7840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:02<00:00, 54.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 0.5161, Test Accuracy: 0.7810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:02<00:00, 54.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Loss: 0.5238, Test Accuracy: 0.7360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:02<00:00, 54.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Loss: 0.5233, Test Accuracy: 0.7770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:02<00:00, 54.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Loss: 0.5144, Test Accuracy: 0.7370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:02<00:00, 54.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Loss: 0.5201, Test Accuracy: 0.7390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:02<00:00, 54.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Loss: 0.5182, Test Accuracy: 0.7650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:02<00:00, 54.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Loss: 0.5215, Test Accuracy: 0.7440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:02<00:00, 53.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Loss: 0.5148, Test Accuracy: 0.7650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:02<00:00, 54.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Loss: 0.5171, Test Accuracy: 0.7840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 125/125 [00:02<00:00, 54.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Loss: 0.5157, Test Accuracy: 0.7730\n",
      "Best accuracy 0.784\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    root_dir = 'qg_data'\n",
    "    dataset = QGDataset(root=root_dir)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    train_dataset, test_dataset = dataset[:train_size], dataset[train_size:]\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "    in_channels = dataset[0].x.shape[1]\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    models = {\n",
    "        \"SimpleGCN\": SimpleGCN(in_channels),\n",
    "        \"GCNModel\": GCNModel(in_channels),\n",
    "        \"GATModel\": GATModel(in_channels),\n",
    "        \"ResidualGCNModel\": ResidualGCNModel(in_channels)\n",
    "    }\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\nTraining {model_name}...\")\n",
    "        model.to(device)\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "        best_acc=0\n",
    "        for epoch in range(1, 21):\n",
    "            loss = train(model, train_loader, optimizer, device)\n",
    "            acc = test(model, test_loader, device)\n",
    "            if(acc>best_acc):\n",
    "                best_acc=acc\n",
    "            print(f\"Epoch {epoch:02d}, Loss: {loss:.4f}, Test Accuracy: {acc:.4f}\")\n",
    "        print(f\"Best accuracy {best_acc}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3402ceb9",
   "metadata": {},
   "source": [
    "# Accuracy \n",
    "\n",
    "Simple GCN ----76.5%<br>\n",
    "GCN Model ----78.1%<br>\n",
    "GAT Model ----77.7%<br>\n",
    "Residual GCN ----78.4%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4d83cc",
   "metadata": {},
   "source": [
    "### Simple GCN\n",
    "It is a simple model with only 2 layers and it cannot capture complex relations\n",
    "\n",
    "### GCN Model\n",
    "The GCN model adds batch normalization that helps to stabalize the learning rates\n",
    "\n",
    "### GAT Model\n",
    "Graph Attention Network applies attention mechanism that weigh the importance of neighbour nodes\n",
    "\n",
    "### Residual GCN\n",
    "It adds recidual connection which helps to preserve low level features and improves gradient flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea71b262",
   "metadata": {},
   "source": [
    "# Future Improvements\n",
    "\n",
    "We can do hyperparameter tuning and increase the epochs and try new and complex models that can increase the accuracy \n",
    "\n",
    "Due to memory and computational issues I have to preprocess the data in batch and we have to convert float64 to float32 \n",
    "I have implemented four simple models that take less computation as fine tuning took a lot of time and increasing layer or hidden dimension had both time and memory issues, so I implemented 4 models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50f103b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
